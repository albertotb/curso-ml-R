<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Conceptos generales de aprendizaje supervisado</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alberto Torres Barrán" />
    <meta name="date" content="2019-03-21" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Conceptos generales de aprendizaje supervisado
## Curso de aprendizaje automático para el INE
### Alberto Torres Barrán
### 2019-03-21

---


# ¿Qué es el Aprendizaje Automático? 

De la Wikipedia:

*Machine learning is a subfield of **computer science** that evolved from the study of **pattern recognition** and computational learning theory in artificial intelligence. In 1959, Arthur Samuel defined machinelearning as a “Field of study that gives computers the ability to learn without being **explicitly programmed**”. Machine learning explores the study and construction of algorithms that can learn from and make predictions on **data**.*

---
class: center, middle

![:scale 60%](./img/machine_learning_2x.png)

Fuente: [xkcd #1838](https://xkcd.com/1838/)

??? 

Aprendizaje automático en la práctica tiene mucho de ingeniería y no tanto de "ciencia"

Mucho prueba y error

La calidad del software ha aumentado mucho en los últimos años, casi cualquiera puede ajustar estos modelos sin conocimientos teóricos profundos

---
class: center, middle

![](./img/cloud.png)

???

* Statistics Más antigua (aprox. 1749), el resto de disciplinas utilizan algunas de sus técnicas: estadística descriptiva, análisis de regresión, inferencia.
* Artificial Intelligence Más moderna, 1940. Algunos problemas que intenta resolver: procesamiento lenguaje natural, planificación, visión por computador, robótica.
* Machine Learning Rama de la IA, 1946. Se utiliza para resolver algunos de los problemas que tiene la IA.
* Pattern Recognition En general se usa como sinónimo de Machine Learning.
* Data Mining Técnicas de modelado estad´ıstico y machine learning aplicadas a un dominio en concreto.
* Data Science Término más moderno, mezcla de todo lo
anterior.

---
class: center

# Data science

![:scale 75%](./img/data-science.png)

Fuente: [R for Data Science](http://r4ds.had.co.nz/)

---

## Casos de éxito

  * Coches autónomos
  
  * Análisis de imágenes médicas
  
  * Procesamiento de lenguaje natural
  
  * AlphaGo y juegos Atari
  
  * Generación de imágenes
  
  * Sistemas de recomendación


---

class: middle, center

## Herramientas

![:scale 75%](./img/top-analytics-data-science-machine-learning-software-2015-2017.jpg)

???

Un poco antigua, en la del 2018 Python supera a R pero ambos son muy populares

---

# Tipos de aprendizaje

Existen diversos tipos de tareas, dependiendo de la información disponible:

- **supervisado**: tenemos acceso a pares de ejemplos entrada-salida

- **no supervisado**: no tenemos acceso a las salidas

- otros (limitando de alguna forma el acceso a las salidas):
  
  * *activo*: el algoritmo puede acceder a la salida para nuevos datos de entrada
  
  * *semi-supervisado*: solo se tienen salidas para algunos datos
  
  * *refuerzo*: no se tiene el valor de la salida, pero si una indicación de lo lejos o cerca que se encuentra

---

# Referencias

   1. Jerome H. Friedman. [Data Mining and Statistics: What's the Connection? (1998)](http://statweb.stanford.edu/~jhf/ftp/dm-stat.pdf)
   
   2. Leo Breiman. [Statistical Modeling: The Two Cultures (2001)](http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)
   
   3. Cross Validated. [What is the difference between data mining, statistics, machine learning and AI (2010).](http://stats.stackexchange.com/questions/5026/what-is-the-difference-between-data-mining-statistics-machine-learning-and-ai)
   
   4. Sakthi Dasan Sekar. [What is the difference between Artificial Intelligence, Machine Learning, Statistics, and Data Mining (2014)](http://shakthydoss.com/what-is-the-difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/)
   
   5. Cross Validated. [What exactly is Big Data? (2015)](http://stats.stackexchange.com/questions/173060/what-exactly-is-big-data)
   
   6. David Donoho. [50 years of Data Science (2015)](http://pages.cs.wisc.edu/~anhai/courses/784-fall15/50YearsDataScience.pdf)


???

Dos culturas:

Una asume que los datos han sido generados por un modelo estocástico específico. 
Otra usa modelos algorítmicos y asume que el mecanismo de generación de los datos es desconocido

---

class: middle, center, inverse

# Aprendizaje supervisado

---

* Tenemos disponibles datos con múltiples observaciones:
   
   * ejemplos (*examples*)
   * muestras (*samples*)
   * ...

--

* Varias variables por observación:
  
  * predictores
  * atributos (*atributes*)
  * características (*features*)
  * covariables (*covariates*)
  * variables independientes
  * variables explicativas
  * ...

--

* Una de ellas es de especial interés: 
  
  * variable respuesta
  * variable dependiente
  * objetivo (*target*)
  * salida (*output*)
  * etiqueta (*label*)
  * ...
  
---

## Objetivos

  1. Predecir el valor de la variable respuesta para nuevas observaciones
   
  2. Obtener información sobre la relación entre las variables independientes y la salida


???

Información sobre la relación, por ej: qué variables son más relevantes

---

## Tipos de problemas

  1. Regresión, si la variable respuesta es continua
  
  2. Clasificación, si la variable respuesta es discreta
  
  3. Otros: por ejemplo,
    
    * salida continua pero valores enteros
    
    * salida discreta pero los valores tienen un orden
  
---

## Aprendizaje estadístico

**Dados**:
* Espacio de las muestras de entrada: `\(\mathcal{X}\)`

* Conjunto de posibles salidas: `\(\mathcal{Y}\)`

* Conjunto de **entrenamiento**: `\(S = \{x_i,\, y_i\}_{i=1}^n\)`, contenido en el espacio `\(\mathcal{X} \times \mathcal{Y}\)`

--

**Objetivo**: 

  * Aprender una regla de predicción (hipótesis), `\(h: \mathcal{X} \rightarrow \mathcal{Y}\)`
  
--

**Asumimos**:
  
  * Los ejemplos se han generado por una distribución de probabilidad desconocida  `\(\mathcal{P}\)`
  
  * Existe una función de pérdida `\(L: \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}\)` que mide como de lejos se encuentra `\(h(x)\)` de `\(y\)`
  
  * El conjunto posible de hipótesis `\((\mathcal{F})\)` es finito
  
  
---

## Minimización del riesgo empírico

Elegir `\(h\)` tal que minimice el riesgo esperado 
`$$R(h) = \int_{\mathcal{X} \times \mathcal{Y}} L(h(x), y)\, dP(x, y)$$`

**Problema**: cómo podemos calcular `\(R\)` si `\(P\)` es desconocida? 

Podemos evaluar la función de pérdida en el conjunto `\(S\)` (riesgo empírico):

`$$\hat{R}(h) = \frac{1}{n}\sum_{i=1}^{n} L(h(x_i), y_i)$$`

Si `\(n\)` suficientemente grande, esperamos que `\(\hat{R}(x) \sim R(x)\)`  `\(\rightarrow\)`
minimizar el riesgo empírico es una buena aproximación de minimizar el riesgo esperado

---

## Descomposición del error

Minimizador del riesgo: `$$h^* = \arg\min_{h \in \mathcal{F}}\, R(h)$$`

Minimizador del riesgo empírico: `$$\hat{h}^* = \arg\min_{h \in \mathcal{F}}\, \hat{R}(h)$$`

Riesgo de Bayes o error de Bayes: `$$R^* = \inf_h\, R(h)$$`

*Nota*: sobre todas las funciones `\(h: \mathcal{X} \rightarrow \mathcal{Y}\)`, no solo las contenidas en `\(\mathcal{F}\)`!!

---

La differencia entre el riesgo y el error de Bayes es:

`$$R(h) - R^* = \underbrace{\big(R(h) - R(\hat{h}^*)\big)}_\text{error optimización} + \underbrace{\big(R(\hat{h}^*) - R(h^*)\big)}_\text{error estimación} + \underbrace{\big(R(h^*) - R^*\big)}_\text{error aproximación}$$` 

--

 **Error optimización**: como de buena es la optimización que llevó a la hipótesis `\(h\)`, relativa a al óptimo del riesgo empírico
   
   * Disminuye al mejorar el algoritmo de optimización
 
--
 
**Error de estimación**: surge por aproximar el riesgo esperado con el riesgo empírico
 
   * Disminuye si aumentamos el conjunto de datos de entrenamiento `\(n\)`
   
--

**Error de aproximación**: surge por aproximar la mejor función posible por la mejor función dentro de `\(\mathcal{F}\)`
 
   * Disminuye si reemplazamos `\(\mathcal{F}\)` por otra clase más flexible


???

Si asumimos que el error de optimización es 0, existe un equilibrio entre el error de estimación y el error de aproximación: por un lado nos interesa elegir clases de funciones muy flexibles, pero por otro estas van a necesitar muchos más ejemplos para aproximar el riesgo esperado con el riesgo empírico de forma correcta

---

## Ejemplo

* Elegimos `\(\mathcal{F}\)` como las clase de funciones del tipo `\(f(x) = w_0 + x^T w\)`

* Función de pérdida: `\(L(y, f(x)) = (y - f(x))^2\)`

* Riesgo empírico: `$$R(w) = \frac{1}{n} \sum_{i=1}^n (y_i - w_0 + x_i^T w)^2$$`

???

En este caso el riesgo es una función cuadrática de los parámetros w

---

## Regresión lineal

Dado el conjunto de entrenamiento `\(S = \{y_i, x_i\}_{i=1}^n\)`


* Agrupamos todos los ejemplos de entrada `\(x_i\)` en una matrix `\(\mathbf{X}\)` de tamaño `\(n \times d\)`

* Agrupamos todas las salidas en un vector columna `\(y\)` de tamaño `\(n \times 1\)`

Expresamos el riesgo empírico en notación matricial: `$$R(w) = (y - \mathbf{X}w)^T (y - \mathbf{X}w)$$`

Gradiente: `$$\nabla_w R(w) = \mathbf{X}^T(y - \mathbf{X}w) = \mathbf{X}^Ty - \mathbf{X}^T\mathbf{X}w$$`

Minimizamos el riesgo empírico: `$$\nabla_w R(w) = 0\quad \Rightarrow \quad  w^* = (\mathbf{X}^T\mathbf{X})^{-1} \mathbf{X}^T y$$`

Recuperamos mínimos cuadrados ordinarios!

???

El término `\(w_0\)` se incluye dentro del vector `\(w\)` añadiendo una columna constante de 1s como primer elemento de X

---

Posibles problemas del modelo:

 * Teóricos: 
   
   1. asumimos que `\(y\)` depende linealmente de `\(x\)`
   
   2. asumimos que el modelo está especificado correctamente (no faltan variables)
   
 * Numéricos:
   
   1. hay menos variables que observaciones
   
   2. no hay dos variables con correlación perfecta


???

En los problemas numéricos, en ambos casos hace que la matriz no tenga rango completo y por tanto no podemos calcular la inversa (de forma exacta!!)

---

## Selección de modelos

* Para medir la calidad del modelo, podemos calcular el riesgo o error empírico en el conjunto de entrenamiento

* Este error se puede disminuir de forma casi arbitraria aumentando la complejidad de la clase de funciones

* **Ejemplo**: en el caso de la regresión lineal, podemos añadir nuevas variables que sean expansiones polinómicas de las ya existentes

* Interesa el **error de generalización**, es decir, el error en nuevas observaciones no usadas para entrenar el modelo

* Partir los datos iniciales en dos conjuntos:
  
   1. conjunto de entrenamiento
   
   2. conjunto de test


???

* El error de test es una buena aproximación del error de generalización

* Estamos asumiendo que ambos provienen de la misma distribución

* Por tanto, la partición tiene que ser aleatoria

---

## Equilibrio sesgo-varianza

* Asumimos que los datos han sido generados por `$$Y = f(X) + \epsilon$$` con `\(\mathbb{E}[\epsilon] = 0\)` y `\(\text{Var}(\epsilon) = \sigma^2\)`

* El error esperado de un estimador `\(\hat{f}(X)\)` en el punto `\(x\)` (usando pérdida cuadrática) es `$$\text{EPE} = \mathbb{E}[(Y - \hat{f}(x))^2]$$`

* Podemos descomponerlo en: `$$\text{EPE} = \underbrace{\Bigl(\mathbb{E}[\hat{f}(x)] - f(x) \Bigr)^2}_{\text{Sesgo}^2} + \underbrace{E\Bigl[\hat{f}(x) - \mathbb{E}[\hat{f}(x)] \Bigr]^2}_{\text{Varianza}} + \underbrace{\vphantom{\Bigl(}\sigma^2}_{\text{Ruido}}$$`

---

class: center, middle

![](./img/bias_variance_dardos.jpg)

---

## Sobreajuste

* Los términos de sesgo y varianza son opuestos: si disminuimos uno aumenta el otro y viceversa

* El término de ruido es inherente a los datos

* Si el modelo es muy simple, el estimador está sesgado y no se ajusta bien a los datos (infraajuste)

* Si el modelo es demasiado complejo, es muy sensible a pequeñas variaciones en los datos

* Además, el error de test será mucho más alto que el error de entrenamiento (**sobreajuste**)

* **Solución**: encontrar un equilibrio que minimice el error en el conjunto de test

---

class: middle, center


![:scale 120%](./img/biasvariance.svg)

---

## Simulación


```r
set.seed(1)
n &lt;- 10
x &lt;- seq(0, 1, length.out = n)
y &lt;- 1.5*x - x^2 + rnorm(n, 0, 0.05)
data &lt;- data.frame(x=x, y=y)

x_new &lt;- seq(0, 1, length.out=500)
newdata &lt;- data.frame(x=x_new)

fit1 &lt;- lm(y ~ x + I(x^2), data=data)
fit2 &lt;- lm(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) 
                 + I(x^6) + I(x^7) + I(x^8) + I(x^9), 
           data=data)
fit3 &lt;- lm(y ~ x, data=data)

y_pred1 &lt;- predict(fit1, newdata=newdata)
y_pred2 &lt;- predict(fit2, newdata=newdata)

ntest &lt;- 1
xtest &lt;- runif(ntest)
ytest &lt;- 1.5*xtest - xtest^2 + rnorm(ntest, 0, 0.05)
```

---


```r
plot(data)
lines(x_new, y_pred1, col="blue")
lines(x_new, y_pred2, col="red")
abline(fit3, col="purple")
points(xtest, ytest, col="darkgreen")
legend("bottomright", 
       c(expression(w[0] + w[1]*x), 
         expression(w[0] + w[1]*x + w[2]*x^2),
         expression(w[0] + w[1]*x + w[2]*x^2 + ldots + w[9]*x^9)), 
       lty=1, lwd=1.5, col=c("purple", "blue", "red"), inset=0.04)
```

&lt;img src="02-supervised_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

---

class: center, middle

![:scale 75%](./img/eslr_ex.png)

Ejemplo de clasificación en 2 dimensiones [ESL]

---

## Vecinos próximos

* Modelo sencillo que usa las observaciones cercanas a `\(x\)` para realizar la predicción: `$$f(x) = \frac{1}{k} \sum_{x_i \in N_k(x)} y_i$$` donde `\(N_k(x)\)` son las `\(k\)` observaciones más cercanas

* Necesaria una métrica (por ej. distancia euclidea)

* Se puede usar tanto para problemas de clasificación como regresión

* Muy sensible al valor de `\(k\)`

---

&lt;img src="02-supervised_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

## Regresión lineal vs vecinos próximos

* La frontera de decisión de la regresión lineal es suave: tiene poca varianza pero potencialmente mucho sesgo

* `\(k\)`-vecinos próximos no asume ninguna estructura en los datos: 

    * la frontera de decisión depende localmente solo de los `\(k\)` puntos más cercanos
    * tiene poco sesgo pero mucha varianza, ya que es muy inestable

* Elegir un modelo u otro depende de los datos del problema


---

## Vecinos próximos: dependencia de `\(k\)`


&lt;img src="02-supervised_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

&lt;img src="02-supervised_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

---

&lt;img src="02-supervised_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---

## Selección de hiper-parámetros

* `\(k\)` es un **hiper-parámetro** que controla la complejidad del modelo

* Podemos realizar un argumento similar a la comparación con la regresión lineal:

   * Para `\(k\)` grande, la frontera es más suave pero tiene (potencialmente) mayor sesgo
   * Para `\(k\)` pequeño la frontera es muy inestable (mayor varianza), pero menos sesgo

* Nota: usar el error de entrenamiento para elegir el valor de `\(k\)` es mala idea, para `\(k=1\)` tenemos error 0!!

* Los distintos valores de `\(k\)` se pueden comparar usando el conjunto de test

---

## Conjunto de validación

 * Elegir `\(k\)` como el valor que minimiza error de test `\(\rightarrow\)` error de test ya **no** es una buena estimación del rendimiento del modelo en nuevos datos
 
 * Lo mismo ocurre si elegimos la clase de funciones (modelo) usando el error de test
 
 * **Solución**: crear un tercer conjunto, conjunto de validación, para seleccionar hiper-parámetros y comparar modelos
 
 * Finalmente, reportar el error de test como estimación del poder de generalización del modelo
 
 * Existen otras formas que veremos más adelante (por ej. validación cruzada)

---

## Regularización

* A menudo se puede reducir la varianza de un estimador a cambio de introducir un pequeño sesgo

* Este término también puede inducir propiedades en la solución, por ej. *sparsity*

* Para ello limitamos la complejidad del modelo añadiendo a la función de pérdida un término de **regularización** `$$\hat{f} = \arg\min_f\; \{L(y, f(x)) + \lambda J(f)\}$$`

* Muchos modelos en aprendizaje automático encajan en este paradigma

---

## Ejemplo

* El estimador de mínimos cuadrados es el mejor estimador no sesgado (mejor = menos varianza) 

* Un término de regularización muy habitual es la norma `\(l_2\)`: `$$||w||^2_2 = w^T w$$`

* Junto con la función de pérdida de la regresión lineal, el modelose conoce como regresión ridge: `$$w^* = \arg\min_w\; \{(y - \mathbf{X}w)^T (y - \mathbf{X}w) + \lambda w^Tw\}$$`

* Tomando derivadas e igualando a 0 la solución es `$$w^* = (\mathbf{X}^T \mathbf{X} + \lambda \mathbf{I})^{-1} (\mathbf{X}^T y)$$` donde `\(\mathbf{I}\)` es la matriz identidad

???


BLUE = Best linear unbiased estimator (teorema de Gauss)

Ahora siempre es invertible para `\(\lambda &gt; 0\)`

&lt;!-- class: middle, center, inverse

# Modelos lineales generalizados 

# Aprendizaje supervisado en la práctica
--&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
